# Comment_Toxicity_Detection
This project aims to classify toxic comments using a combination of LSTM and CNN models. The dataset used for training is train.csv, which contains comment texts and corresponding toxicity labels. The models are built using TensorFlow and Keras, and the project is implemented in Google Colab. Classifies the text into five different categories: toxic, severe toxic, obscene, threat, and insult. The interface is implemented using gradio.

Language:Python \n
Libraries: tensorflow, keras, pandas, matplotlib, scikit-learn, gradio
![image](https://github.com/aryanb203/Comment_Toxicity_Detection/assets/43962969/c0efdf4f-35d6-48f4-a5a1-8661298db199)
![image](https://github.com/aryanb203/Comment_Toxicity_Detection/assets/43962969/ba5b5c5f-9720-42ff-b193-96496705e666)
